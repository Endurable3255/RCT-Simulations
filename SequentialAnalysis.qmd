---
title: "Sequential Analysis"
author: "Johannes Schwenke"
date: "2024-06-26"
format: 
  revealjs:
    logo: Logo_Unibas_USB_ALL.svg
    theme: default
editor: visual
---

```{r Setup}
#| label: load-packages
#| include: false
#| warning: false

library(rpact)
library(tidyverse)
library(glue)
library(ggplot2)
library(ggokabeito)


options(
  # set default colors in ggplot2 to colorblind-friendly
  # Okabe-Ito and Viridis palettes
  ggplot2.discrete.colour = ggokabeito::palette_okabe_ito(),
  ggplot2.discrete.fill = ggokabeito::palette_okabe_ito(),
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  # set theme font and size
  book.base_family = "sans",
  book.base_size = 14
)

# set default theme
theme_set(
  theme_minimal(
    base_size = getOption("book.base_size"),
    base_family = getOption("book.base_family")
  ) %+replace%
    theme(
      panel.grid.minor = element_blank(),
      legend.position = "bottom"
    )
)
```

## One year ago... {.smaller}

![Unplanned interim analysis of effectiveness of meningococcal group B vaccine to prevent gonorrhoea.](images/DoxyVAC2.png){#DoxyVac_Interim}

## But then ... {.smaller}

. . .

"Full analysis of French STI study *dashes hopes* for a gonorrhoea vaccine".

![Effectiveness of meningococcal group B vaccine at final analysis.](images/DoxyVAC4.png){#DoxyVAC_final}

## Matthias was not amused {.smaller}

For had he himself not published on the subject more almost 17 (!) years ago?

![](images/Matthias_Paper.png)

> "Compelling evidence suggests that trials stopped early for benefit systematically overestimate treatment effects, sometimes by a large amount. Unresolved controversies in trials stopped early for benefit include ethical and statistical problems in the interpretation of results."

# What's all the fuss about interim analysis?

## First, back to the basics

::: incremental
-   p-values and their distributions
-   error control
-   optional stopping
:::

## Back to the basics: p-values

What was the definition of a p-value again?

. . .

> The definition of a p-value is the probability of observing the sample data, or more extreme data, assuming the null hypothesis is true.[^1]

[^1]: Lakens, [Improving Your Statistical Inferences](https://lakens.github.io/statistical_inferences/)

. . .

-   P-values are a statement about the **probability of data**, [not]{.underline} a statement about the probability of a hypothesis or the probability of a theory.

## Distribution of p-values under $H_0$

```{r fig-pdistr2, cache = TRUE, echo=FALSE}
#| fig-cap: "Distribution of *p*-values when the null hypothesis is true. By <a href='https://lakens.github.io/statistical_inferences/01-pvalue.html#fig-pdistr2'>Daniel Lakens</a>."

#Set number of simulations
nSims <- 100000 #number of simulated experiments
p <-numeric(nSims) #set up empty variable to store all simulated *p*-values

for (i in 1:nSims) { # for each simulated experiment
  x <- rnorm(n = 71, mean = 100, sd = 15) # Simulate data
  y <- rnorm(n = 71, mean = 100, sd = 15) # Simulate data
  p[i] <- t.test(x, y)$p.value # store the *p*-value
}
  
bars<-20
#Plot figure
op <- par(mar = c(5,7,4,4)) #change white-space around graph
hist(p, breaks=bars, xlab="p-values", ylab="number of p-values\n", axes=FALSE,
     main=paste("p-value distribution when the null hypothesis is true"),
     col="grey", xlim=c(0,1), ylim=c(0, nSims))
axis(side=1, at=seq(0,1, 0.1), labels=seq(0,1,0.1))
axis(side=2, at=seq(0,nSims, nSims/4), labels=seq(0,nSims, nSims/4), las=2)
abline(h=nSims/bars, col = "red", lty=3, lwd = 2)

```

## Distribution of p-values under $H_A$

```{r fig-pdistr1, cache = TRUE, echo=FALSE}
#| fig-cap: "Distribution of *p*-values when power = 50%. By <a href='https://lakens.github.io/statistical_inferences/01-pvalue.html#fig-pdistr1'>Daniel Lakens</a>." 

#Set number of simulations
nSims <- 100000 # number of simulated experiments
p <- numeric(nSims) # set up empty variable to store all simulated *p*-values
bars <- 20

for (i in 1:nSims) { # for each simulated experiment
  x <- rnorm(n = 71, mean = 100, sd = 15) # Simulate data
  y <- rnorm(n = 71, mean = 105, sd = 15) # Simulate data
  p[i] <- t.test(x, y)$p.value # store the *p*-value
}
  
#Plot figure
op <- par(mar = c(5,7,4,4)) #change white-space around graph
hist(p, breaks=bars, xlab="p-values", ylab="number of p-values\n", axes=FALSE,
     main=paste("p-value Distribution with 50% power"),
     col="grey", xlim=c(0,1), ylim=c(0, nSims))
axis(side=1, at=seq(0,1, 0.1), labels=seq(0,1,0.1))
axis(side=2, at=seq(0,nSims, nSims/4), labels=seq(0,nSims, nSims/4), las=2)
abline(h=nSims/bars, col = "red", lty=3, lwd = 2)

```

## Distribution of p-values under $H_A$

```{r fig-paradox, echo=FALSE}
#| fig-cap: "*P*-value distribution for 0 (grey horizontal line, 50 percent power (black solid curve), and 99 percent power (black dotted curve, where *p*-values just below 0.05 are more likely when $H_0$ is true than when $H_1$ is true). By <a href='https://lakens.github.io/statistical_inferences/01-pvalue.html#fig-pdft'> Daniel Lakens</a>."
# Lindley plot

n <- 150
p <- 0.05
ymax <- 25 # Maximum value y-scale (only for p-curve)

# Calculations

# p-value function
pdf2_t <- function(p) 0.5 * dt(qt(p / 2, 2 * n - 2, 0), 2 * n - 2, ncp) / dt(qt(p / 2, 2 * n - 2, 0), 2 * n - 2, 0) + dt(qt(1 - p / 2, 2 * n - 2, 0), 2 * n - 2, ncp) / dt(qt(1 - p / 2, 2 * n - 2, 0), 2 * n - 2, 0)

plot(-10,
  xlab = "p-value", ylab = "Density", axes = FALSE,
  main = "p-value distribution for d = 0, 50% power, and 99% power", xlim = c(0, 1), ylim = c(0, ymax), cex.lab = 1.2, cex.main = 1.2, cex.sub = 1
)
axis(side = 1, at = seq(0, 1, 0.05), labels = formatC(seq(0, 1, 0.05), format = "f", digits = 2), cex.axis = 1)
# Draw null line
ncp <- (0 * sqrt(n / 2)) # Calculate non-centrality parameter d
curve(pdf2_t, 0, 1, n = 1000, col = "grey", lty = 1, lwd = 2, add = TRUE)
# Draw 50% low power line
n <- 146
d <- 0.23
se <- sqrt(2 / n) # standard error
ncp <- (d * sqrt(n / 2)) # Calculate non-centrality parameter d
curve(pdf2_t, 0, 1, n = 1000, col = "black", lwd = 3, add = TRUE)
# Draw 99% power line
n <- 150
d <- 0.5
se <- sqrt(2 / n) # standard error
ncp <- (d * sqrt(n / 2)) # Calculate non-centrality parameter d
curve(pdf2_t, 0, 1, n = 1000, col = "black", lwd = 3, lty = 3, add = TRUE)


```

## Error control

```{r fig-errortypes, echo = FALSE, fig.cap='Difference between Type 1 and Type 2 errors. Figure made by <a href="https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/">Paul Ellis</a>'}

knitr::include_graphics("images/type1type2error.jpg")

```

## Error control {.smaller}

The desire to make scientific claims based on a methodological procedure that (when the assumptions are met), **limits the percentage of incorrect claims to a desired maximum value**.

. . .

$\rightarrow$ significance level $\alpha$!

. . .

```{r fig-pdistr3, cache = TRUE}
#| fig-height: 4
#| fig-width: 10

#Set number of simulations
nSims <- 100000 #number of simulated experiments
p <-numeric(nSims) #set up empty variable to store all simulated *p*-values

for (i in 1:nSims) { # for each simulated experiment
  x <- rnorm(n = 71, mean = 100, sd = 15) # Simulate data
  y <- rnorm(n = 71, mean = 100, sd = 15) # Simulate data
  p[i] <- t.test(x, y)$p.value # store the *p*-value
}
  
bars<-20
#Plot figure
op <- par(mar = c(5,7,4,4)) #change white-space around graph
hist(p, breaks=bars, xlab="p-values", ylab="number of p-values\n", axes=FALSE,
     main=paste("p-value distribution when the null hypothesis is true"),
     col="grey", xlim=c(0,1), ylim=c(0, nSims))
axis(side=1, at=seq(0,1, 0.1), labels=seq(0,1,0.1))
axis(side=2, at=seq(0,nSims, nSims/4), labels=seq(0,nSims, nSims/4), las=2)
abline(h=nSims/bars, col = "red", lty=3, lwd = 2)
abline(v=0.05, col = "blue", lty = 3, lwd = 2)

```

## Optional stopping leads to Type-I error inflation

. . .

![Simulated p-values for each additional observation when the null is true. By [Daniel Lakens](https://lakens.github.io/statistical_inferences/02-errorcontrol.html#fig-animatep).](images/animatep.gif)

# How can we repeatedly analyze incoming data without Type-I error inflation?

# Sequential analysis

## Sequential analysis - Terminology

::: incremental
-   **Look**: analyzing all the collected data up to specific point
-   **Interim** **analysis**: analysis at all but the final look
-   **Final** **analysis**: Analysis at the final look
-   **overall** $\alpha$ **- level:** accepted Type I error rate across all looks
:::

## Tests in sequential analysis are dependent

-   Test at look 2 combines th old data collected at look 1 with new data at look 2

-   Type 1 error rate inflates less quickly compared to independent tests

$\rightarrow$ enables more efficient and flexible solutions to controlling error rates

## Critical z-values {.smaller}

::: columns
::: {.column width="70%"}
```{r fig-pboundaries, cache = TRUE}
#| fig-cap: critical Z-values for 2 looks, overall $\alpha$ of 0.05 and Pocock correction.
#| fig-height: 7


design <- getDesignGroupSequential(
    kMax = 2,
    typeOfDesign = "P",
    alpha = 0.05,
    sided = 2
)

plot(design, type = 1)
```
:::

::: {.column width="30%"}
::: incremental
$\alpha$-levels:

-   Pocock: 0.0294; 0.0294

-   Bonferroni: 0.25; 0.25

    -   overly conservative
:::
:::
:::

. . .

$$Pr\{Z_n \geq c_1\} + Pr\{Z_n < c_1, Z_N \geq c_2\} = \alpha$$

## Simulation parameters {.smaller}

```{r}
#| warning: false
source("presentation/figures.R")
```

-   Consider a parallel-group 1:1 randomized trial witha binary outcome
-   Probability of failure (e.g., mortality) is `r sim1$death0` in control group
-   Suppose that intervention is in fact effective:
    -   risk (of mortality) is `r sim1$death1` in intervention group
    -   OR: `r round(sim1$trueOR, digits = 2)`
-   `r max(sim1$analyses_nPatients)` Patients per trial

## One Trial {.smaller}

-   $P(Event)$ of `r sim1$death0` in control group, `r sim1$death1` in intervention group
-   `r max(sim1$analyses_nPatients)` Patients per Trial, `r max(sim1$df_not_stopped_interim$trial)` trials.
-   *True* OR: `r round(sim1$trueOR, digits = 2)`

. . .

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5

p2.1
```

## One Trial {.smaller}

-   $P(Event)$ of `r sim1$death0` in control group, `r sim1$death1` in intervention group
-   `r max(sim1$analyses_nPatients)` Patients per Trial, `r max(sim1$df_not_stopped_interim$trial)` trials.
-   *True* OR: `r round(sim1$trueOR, digits = 2)`

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5

p2.2
```

## 100 Trials {.smaller}

-   $P(Event)$ of `r sim1$death0` in control group, `r sim1$death1` in intervention group
-   `r max(sim1$analyses_nPatients)` Patients per Trial, `r max(sim1$df_not_stopped_interim$trial)` trials.
-   *True* OR: `r round(sim1$trueOR, digits = 2)`

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5
#| warning: false

p2.3
```

## Trials with $p < \alpha$ at look 1 {.smaller}

-   $P(Event)$ of `r sim1$death0` in control group, `r sim1$death1` in intervention group
-   `r max(sim1$analyses_nPatients)` Patients per Trial, `r max(sim1$df_not_stopped_interim$trial)` trials.
-   *True* OR: `r round(sim1$trueOR, digits = 2)`

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5
#| warning: false

p2.4
```

## Trials with $p < \alpha$ at look 1 {.smaller}

-   $P(Event)$ of `r sim1$death0` in control group, `r sim1$death1` in intervention group
-   `r max(sim1$analyses_nPatients)` Patients per Trial, `r max(sim1$df_not_stopped_interim$trial)` trials.
-   *True* OR: `r round(sim1$trueOR, digits = 2)`

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5
#| warning: false

p2.5
```

## OR *conditional* on efficacy{.smaller}

```{r}
median_OR_look1_cond <- sim1$df_stopped_interim |> filter(first_success_index == 1) |> summarize(median_OR = median(or)) |> pull()

median_OR_look1_uncond <- sim1$df_not_stopped_interim |> filter(look == 1) |> summarize(median_OR = median(or)) |> pull()
```

-   *True* OR: `r round(sim1$trueOR, digits = 2)`
-   Median OR of trials stopped early: `r median_OR_look1_cond`
-   Median OR of all trials at look 1: `r median_OR_look1_uncond`

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5

p2.5
```

## Similar Type II error rate {.smaller .scrollable}

```{r}
pvalues_at_final <- sim1$df_not_stopped_interim |> filter(look == 2) |> select(pvalue) |> pull()
power_1_look <- mean(pvalues_at_final < 0.05)*100
```

-   `r (sim1$df_not_stopped_interim |> group_by(trial) |> slice_head(n = 1) |> ungroup() |> count(overall_success))[2,2]` out of ``r max(sim1$df_not_stopped_interim$trial)` trials with $p < \alpha$, with 2 Looks and Pocock correction
-   `r power_1_look`  out of `r max(sim1$df_not_stopped_interim$trial)` when not doing interim analysis an one-tailed $\alpha$ of 0.05 at final analysis

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 4.5
#| warning: false

plot_interim_or_OvScs(data = sim1$df_stopped_interim, true_effect = sim1$trueOR, x_breaks = sim1$analyses_nPatients, design = sim1$design, event_rate = sim1$death0, title_suffix = "Stopped at interim")
```
